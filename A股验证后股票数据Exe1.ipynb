{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8be2b99-85c3-4638-a229-692791b5528b",
   "metadata": {},
   "source": [
    "# A股验证后股票数据Exe1 V1 （202411）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7544aa-a5fb-42db-a2c8-675b1877e6e7",
   "metadata": {},
   "source": [
    "# Validated Stock Data of A-share Stock In Chinese Market Execute Document V1 （202411）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f11542e5-b985-49c8-b55e-46f165da22d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "today = datetime.datetime.today()\n",
    "current_date=today.strftime(\"%Y%m%d\")  #用于标记此次处理的数据表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb147ce-8ecf-4b8c-9b58-5ac25946c4f6",
   "metadata": {},
   "source": [
    "## 1. 概述\n",
    "本文通过以下几步获得验证的股票数据，数据源主要是AKShare源，通过国泰君安App软件导出的数据进行比对后，保存入数据库供调用。分为以下几步：\n",
    "- A股清单从实时行情中获取\n",
    "- 通过AKShare实时行情、基本面信息和国泰君安App软件比对后获得A股可信清单\n",
    "- 将可信A股清单保存入内存以result(DataFrame)形式\n",
    "- 从国泰君安APP中获取历史数据（不复权）作为A股历史数据验证数据\n",
    "- 将国泰君安A股历史验证数据（不复权）通过AKShare在线获取股票历史不复权数据与验证数据比对后，获得可信A股历史数据，存入verifystock数据库gtja表（DolphinDB)\n",
    "- 根据在可信A股历史验证数据中的股票代码，从AKShare网上再下载所需的复权信息（后复权为主，但可自由选择），存入dailystock数据库ashare表（DolphinDB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601b5e4f-4fb8-48a3-81b2-e99d065551fe",
   "metadata": {},
   "source": [
    "## 1. A股清单和CDA验证\n",
    "我们采用sqlite数据库保存A股清单\n",
    "### 1.1 AkShareA股清单下载\n",
    "通过实时行情数据-京沪深A股栏目,提取所有AKShare股票A股清单\n",
    "（ https://akshare.akfamily.xyz/data/stock/stock.html#id1 ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3516ed8d-3a00-4c51-8f8d-320740264898",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import akshare as ak\n",
    "import numpy as np\n",
    "import logging\n",
    "import json\n",
    "\n",
    "#disable future warnings of akshare package\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# derived from CQF E3 Assginment, delete the trans frunction.\n",
    "# function of data acquisition: if there's table in database use \n",
    "#     native data, else retrieve from akShare Source.\n",
    "# AKShareFunc -- AKShare function to retrieve data from web source,\n",
    "# paraDict -- parameters of AKShare function in the form of Dictionary,\n",
    "# tablename -- table name to store data(svm.db),\n",
    "# filelink -- database file link,\n",
    "def get_data(AKShareFunc,paraDict,tablename,filelink,inform=True):\n",
    "    conn = sqlite3.connect(filelink)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"SELECT name FROM sqlite_master WHERE type='table'\\\n",
    "    AND name='{tablename}'\")\n",
    "    result = cursor.fetchone()\n",
    "    dataEng=pd.DataFrame()\n",
    "    if not result:\n",
    "        if inform:\n",
    "            print('get data from source.')\n",
    "        fundData = AKShareFunc(**paraDict)\n",
    "        fundData.to_sql(tablename, conn,index=False)\n",
    "    else:\n",
    "        if inform:\n",
    "            print('read from sql.')\n",
    "    funddataEng=pd.read_sql(f\"SELECT * FROM {tablename}\", conn)\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    return funddataEng\n",
    "\n",
    "#生成stock symbol数据库（sqlite3)\n",
    "def gen_stocksymb(filelink,tablename):\n",
    "    AKShareFunc=ak.stock_zh_a_spot_em\n",
    "    paraDict={}\n",
    "    AKrealtimeA = get_data(AKShareFunc,paraDict,tablename,filelink)\n",
    "    print(f'从{tablename}获得AKShare股票代码清单。')\n",
    "    return {'date':formatted_date,'df':AKrealtimeA}\n",
    "\n",
    "tablename='stockSymb_AK'+current_date\n",
    "filelink='Data/stock.db'\n",
    "\n",
    "#分步代码，需要分步运行时解除以下注释\n",
    "#AKrealtimeA=gen_stocksymb(filelink,tablename)['df']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84552cec-9f05-4dee-8cd8-2a5bfbf79171",
   "metadata": {},
   "source": [
    "### 1.2 国泰君安富易APP所有A股清单\n",
    "#### 1.2.1 沪深京盘后数据下载维护\n",
    "点击“行情/A股市场”，设置/盘后数据下载（1992-1-1至今）\n",
    "![gtja_afterdata.png](image/gtja_afterdata.png)\n",
    "\n",
    "#### 1.2.2 导出数据xls\n",
    "- 选择APP显示A股行情：点击“行情/A股市场”\n",
    "- 菜单选择：“设置/数据导出”（目标文件夹：共享本地目录/每日盘前/全部A股241203.xls)\n",
    "- 将源数据复制到待处理数据池：(/Users/mac/Downloads/同步空间/notebook/薛猫选股/A股验证股票数据/Data/manual/全部Ａ股20241203.xls）。\n",
    "\n",
    "#### 1.2.3 手工整理csv\n",
    "形成文档\"Data/gtjaA20241203.csv\"，主要整理：  \n",
    "- 去掉最后一行“数据来源:通达信\"\n",
    "- 同时检查单个或者多个0开头的股票代码是否是文本形式\n",
    "- 将空值\"--\"转换为-1\n",
    "- 将xls转换为csv\n",
    "![guotaiA.png](image/guotaiA.png)\n",
    "\n",
    "#### 1.2.4 读入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9706fc9-a042-4308-8051-6b03f7eea462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datalink=f'Data/gtjaA20241203.csv'   #手工保存国泰君安App数据\n",
    "#分步代码，需要分步运行时解除以下注释\n",
    "#gt_A=pd.read_csv(datalink,dtype={\"代码\":str})\n",
    "#gt_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707affee-a32a-4ead-b505-3b3fd845c198",
   "metadata": {},
   "source": [
    "### 1.3 A股清单数据比对\n",
    "#### 1.3.1 比对函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2007302-2f18-46dd-9139-46fa04e7b709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#find two difference of DataFrame column value items regardless of its sequences. \n",
    "# 比对两个不同的DataFrame相同列和相同索引处数据的差异，并给出报告\n",
    "# NOT SUITABLE FOR INDEX COMPARISON ON COLUMNS FOR SEQUENCE REDUPLICATED VALUES\n",
    "# colnameList: List of the names of columns to be compared\n",
    "# return \n",
    "#  colname:\n",
    "#  df12common: df1与公共部分差异\n",
    "#  df22common: df2与公共部分差异\n",
    "#  df1todf2:  df1有而df2没有的股票\n",
    "#  df2todf1:  df2有而df1没有的股票\n",
    "# edited 2024-10-7 can be \n",
    "def compareDiff(df1,df2,colnameList=None):\n",
    "    diffDf=pd.DataFrame()\n",
    "    if colnameList==None:\n",
    "        colnameList=list(set(df1.columns.tolist()+df2.columns.tolist()))\n",
    "    for colname in colnameList:\n",
    "        df1Arr=set(df1[colname])\n",
    "        df2Arr=set(df2[colname])\n",
    "\n",
    "        common=df1Arr & df2Arr\n",
    "        df12common=(len(df1Arr)-len(common))/len(df1Arr)\n",
    "        df22common=(len(df2Arr)-len(common))/len(df2Arr)\n",
    "        \n",
    "        df1todf2=df1Arr-df2Arr\n",
    "        df2todf1=df2Arr-df1Arr\n",
    "        \n",
    "        #change decimals to strings if values are numbers\n",
    "        if len(df1todf2)>0 and type(list(df1todf2)[0])!='str':\n",
    "            df1todf2=set(map(str,df1todf2))\n",
    "        if len(df2todf1)>0 and type(list(df2todf1)[0])!='str':\n",
    "            df2todf1=set(map(str,df2todf1))\n",
    "            \n",
    "        df1Diff=','.join(df1todf2)\n",
    "        df2Diff=','.join(df2todf1)\n",
    "        #print(df1Diff,df2Diff)\n",
    "        \n",
    "        # colname: name of compared columns\n",
    "        # df12common,df22common: Difference ratio with intersection of DataFrames(df1,df2)\n",
    "        # dif1Diff,dif2Diff: List of Differences\n",
    "        newdf=pd.DataFrame({\n",
    "            'colname':[colname],\n",
    "            'df12common':[df12common],\n",
    "            'df22common':[df22common],\n",
    "            'df1Diff':[df1Diff],\n",
    "            'df2Diff':[df2Diff]\n",
    "        })\n",
    "        diffDf=pd.concat([diffDf,newdf],ignore_index=True)\n",
    "\n",
    "    return diffDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46122960-80da-4305-8cfd-e0c588dd0bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf1=pd.DataFrame({'date':['2020-01-01','2020-01-02','2020-01-03'],'value':[3,4,5]})\\ndf1.set_index('date',inplace=True)\\ndf2=pd.DataFrame({'date':['2020-01-02','2020-01-03','2020-01-04'],'value':[4,4.9,5]})\\ndf2.set_index('date',inplace=True)\\ncompareDiff(df1,df2)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 需要运行测试时，取消注释\n",
    "#df1=pd.DataFrame({'date':['2020-01-01','2020-01-02','2020-01-03'],'value':[3,4,5]})\n",
    "#df1.set_index('date',inplace=True)\n",
    "#df2=pd.DataFrame({'date':['2020-01-02','2020-01-03','2020-01-04'],'value':[4,4.9,5]})\n",
    "#df2.set_index('date',inplace=True)\n",
    "#compareDiff(df1,df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d66f46f-0176-4dd5-bd76-c00de060a252",
   "metadata": {},
   "source": [
    "#### 1.3.2 AkShare和国泰君安A股清单差异分析\n",
    "国泰君安与AkShare数据公共部分：common  \n",
    "国泰君安数据与公共部分完全重合，差异为：0%  \n",
    "AkShare数据与公共部分差异：5.09%  \n",
    "结论：AkShare数据比国泰君安多出287条。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43642683-142b-4677-8e16-3af8083e8546",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#分步代码，需要分步运行时解除以下注释\n",
    "#AkGtjaDifDf=compareDiff(gt_A,AKrealtimeA,['代码'])\n",
    "#AkGtjaDifDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e674d625-df0f-4c2f-8e03-dcf042342c5f",
   "metadata": {},
   "source": [
    "AkShare数据的差异部分列表(比国泰君安多出的股票)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a38a980-c465-4cb8-8ec0-6ad054646d69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#分步代码，需要分步运行时解除以下注释\n",
    "#AkGtjaDifList=AkGtjaDifDf['df2Diff'].tolist()[0].split(',')\n",
    "#df_filtered = AKrealtimeA[AKrealtimeA['代码'].isin(AkGtjaDifList)]\n",
    "#df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b4cff4-1eda-49b7-92a3-d90a2bd4a7a1",
   "metadata": {},
   "source": [
    "这些股票都没有最新价信息（即AkShare比国泰君安多出部分的股票清单与没有实时报价信息的股票清单重合————即国泰君安股票清单与AkShare股票清单在具备实时报价信息上一致）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5ee6601-f5b8-46da-9e57-88660d1d6cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#分步代码，需要分步运行时解除以下注释\n",
    "#df_filtered2=df_filtered[df_filtered['最新价'].isna()]  #stocks without current quotes\n",
    "#AkDifAkNulldf=compareDiff(df_filtered,df_filtered2,['代码'])\n",
    "#AkDifAkNulldf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260804e6-507e-45fc-b177-d55bcbd28c76",
   "metadata": {},
   "source": [
    "#### 1.3.3 补充说明：AkShare 两网和退市股票并不包括全部退市股票\n",
    "AkShare溢出的股票清单并不在 AkShare 两网及退市股票信息中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdf07b6d-6533-4fde-9806-a36556ddc184",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import akshare as ak\n",
    "\n",
    "#分步代码，需要分步运行时解除以下注释\n",
    "\n",
    "##AkShare delisted stocks\n",
    "#AKShareFunc=ak.stock_zh_a_stop_em\n",
    "#paraDict={}\n",
    "#tablename='delist'+current_date\n",
    "\n",
    "#AKdelist = get_data(AKShareFunc,paraDict,tablename,filelink)[['代码','名称']]\n",
    "\n",
    "#filtereddf3=compareDiff(df_filtered,AKdelist,['代码'])\n",
    "#filtereddf3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37446c7-2951-44bd-a852-c7cd8df57810",
   "metadata": {},
   "source": [
    "### 1.4 A股清单做基本面信息验证\n",
    "AkShare数据有基本面信息接口，我们查询此基本面信息接口，做以下两件事情： \n",
    "- 与我们保存的A股清单的“代码”和“名称”做验证，防止股票代码信息与股票信息错位（见 [涨停板敢死队](../涨停板敢死队/涨停板敢死队.ipynb) 2.2.4.2 获得基准验证数据：国泰君安富易App2020年数据集）\n",
    "- 增加IPO日期（用于校验历史数据起始日期）\n",
    "\n",
    "对A股清单的代码和名称做交叉验证。本步骤需要人工处理，因为简称可能有所不同，但标的还是一个。代码如果需要从下文再重新运行，需要手动删除faillist.pkl文件，避免跳过检查和IPO添加环节。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8c35e88-1b08-41c7-a175-6130bf4f6acf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A is Brief of B which means:\n",
    "# 1)all characters in A are in B\n",
    "# 2)the order of characters in A is the same as those in B\n",
    "def isBriefOf(A, B):\n",
    "    lenA, lenB = len(A), len(B)\n",
    "    i, j = 0, 0\n",
    "    \n",
    "    while i < lenA and j < lenB:\n",
    "        if A[i] == B[j]:\n",
    "            i += 1\n",
    "        j += 1\n",
    "    return i == lenA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbcdc65e-c187-4a17-92f7-c0254d149c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Save a temporary file named \"faillist.pkl\" in the current directory to support the resumption of the network query for fundamental information. \n",
    "# To start over, please manually delete the file or choose loadTemp=False.\n",
    "# AShareDf: the target stock DataFrame to be checked\n",
    "# addDate: add IPO date information to the DataFrame\n",
    "# fix: fixed automatically if there's in accordance with the source\n",
    "# loadtemp: load temp file which stores last source query, False to restart all queries\n",
    "def checkFoundamental(AShareDf, addDate=True, fix=False, loadtemp=True):\n",
    "    mismatch = []\n",
    "    checkList = None\n",
    "    faillist = []\n",
    "    resdf = AShareDf\n",
    "    i = 0\n",
    "    failfile='faillist.pkl'\n",
    "    foundfilepath='Data/found.csv'\n",
    "    checkAkshare=True\n",
    "    \n",
    "    if loadtemp:\n",
    "        if os.path.exists(failfile):\n",
    "            with open(failfile, 'rb') as temp_file:\n",
    "                checkList = pickle.load(temp_file)  # support resumable transfer \n",
    "            if os.path.exists(foundfilepath):\n",
    "                resdf=pd.read_csv(foundfilepath)\n",
    "                checkAkshare=False\n",
    "        else:\n",
    "            checkList = AShareDf['代码'].tolist()\n",
    "    else:\n",
    "        checkList = AShareDf['代码'].tolist()\n",
    "\n",
    "    # for the stability of AKShare source, we retreat 3 times if fail\n",
    "    while i < 3 and len(checkList) > 0 and checkAkshare:\n",
    "        print(f'Try time {i+1}:')\n",
    "        for s in checkList:\n",
    "            msg = f'checking {s}...'\n",
    "            print(f'{msg:<100}', end='\\r')\n",
    "            df_row=AShareDf.loc[AShareDf['代码'] == s, '名称']\n",
    "            if not df_row.empty:\n",
    "                df_value = df_row.values[0]\n",
    "\n",
    "                querySuccess=False\n",
    "                try:\n",
    "                    s_df = ak.stock_individual_info_em(symbol=s)\n",
    "                    querySuccess=True\n",
    "                except Exception as e:\n",
    "                    msg = f'{e}. Try {s} another {2-i} times.'\n",
    "                    print(f'{msg:<100}', end='\\r')\n",
    "                    faillist.append(s)\n",
    "\n",
    "                if querySuccess:\n",
    "                    s_value = s_df.loc[s_df['item'] == '股票简称', 'value'].values[0]\n",
    "\n",
    "                    # delete the spaces\n",
    "                    df_value_no_space = re.sub(r'\\s+', '', df_value)\n",
    "                    s_value_no_space = re.sub(r'\\s+', '', s_value)\n",
    "\n",
    "                    # delete the special prefixes ('XD','N','ST','C') of stock names\n",
    "                    # XD: Ex-dividend and ex-rights\n",
    "                    # N: Newly IPO stocks the first day\n",
    "                    # C: Newly IPO stocks the first week\n",
    "                    # ST:Special Treatment\n",
    "                    df_value_trim = re.sub(r'^XD|^N|^ST|\\*ST$|C', '', df_value_no_space)\n",
    "                    s_value_trim = re.sub(r'^XD|^N|^ST|\\*ST$|C', '', s_value_no_space)\n",
    "\n",
    "                    # get Chinese Characters\n",
    "                    df_value_chinese = re.findall(r'[\\u4e00-\\u9fff]', df_value_trim)\n",
    "                    s_value_chinese = re.findall(r'[\\u4e00-\\u9fff]', s_value_trim)\n",
    "\n",
    "                    #whether the two strings are at least one direction inclusion relationship\n",
    "                    isBrief=isBriefOf(s_value_chinese,df_value_chinese) or isBriefOf(df_value_chinese,s_value_chinese)\n",
    "\n",
    "                    # 判断两个字符串相等\n",
    "                    if df_value_no_space == s_value_no_space or isBrief:\n",
    "                        msg = f\"code: {s} checked: matched codes.\"\n",
    "                        print(f'{msg:<100}', end='\\r')\n",
    "                        pass\n",
    "                    else:\n",
    "                        mismatch.append({'code': s, 'source': s_value, 'target': df_value})\n",
    "                        msg = f\"code: {s},df({df_value}) vs source({s_value}) mismatched.\"\n",
    "                        if fix:\n",
    "                            AShareDf.loc[AShareDf['代码'] == s,'名称'] = s_value\n",
    "                            msg += \"replaced.\"\n",
    "                        print(f'{msg:<100}', end='\\r')\n",
    "\n",
    "                    # add IPO date to DataFrame\n",
    "                    if addDate:\n",
    "                        ipostr = str(s_df.loc[s_df['item'] == '上市时间', 'value'].values[0])\n",
    "                        print(f'adding {msg:<100} IPO:{ipostr}', end='\\r')\n",
    "                        resdf.loc[resdf['代码'] == s, 'IPO'] = datetime.datetime.strptime(ipostr, \"%Y%m%d\") if ipostr!='-' else np.nan\n",
    "                else:\n",
    "                    faillist.append(s)\n",
    "                    msg = f'{s} 在faillist.pkl文件中有该股票代码，但是在目标dataframe中没有找到，可能来源于上一次的记录，解决此问题，可以删除上一次记录faillist.pkl后重试.'\n",
    "                    print(msg)\n",
    "        print(f'faillist({len(faillist)}):{faillist}')\n",
    "        checkList = faillist\n",
    "        faillist = []\n",
    "        i += 1\n",
    "    if checkList == []:\n",
    "        msg = 'All codes are checked'\n",
    "        msg += ' and fixed.' if fix else '.'\n",
    "    else:\n",
    "        msg = f'Check the following manually because of the inquiry failure(total {len(checkList)}): \\n{checkList}'\n",
    "    \n",
    "    if loadtemp:\n",
    "        with open(failfile, 'wb') as temp_file:\n",
    "            pickle.dump(checkList, temp_file)\n",
    "    \n",
    "    print(f'{msg:<100}', end='\\r')\n",
    "    \n",
    "    return {'mismatch': mismatch, 'df': resdf, 'fail': checkList}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86b477b3-7425-4395-a07e-c86a92aadc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#分步代码，需要分步运行时解除以下注释\n",
    "#checkFound=checkFoundamental(gt_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd0f240-bd37-418d-8723-f8b26fe0604f",
   "metadata": {},
   "source": [
    "不匹配的股票清单：原因是曾用名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "512905e3-86a4-4575-ad67-2623e3d552af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#分步代码，需要分步运行时解除以下注释\n",
    "#checkFound['mismatch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af50db67-65d6-45dc-93c3-94294938f00d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#分步代码，需要分步运行时解除以下注释\n",
    "#gt_A_val=checkFound['df']\n",
    "#gt_A_val.to_csv(foundfilepath)\n",
    "#gt_A_val[['代码','名称','IPO']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4673c359-85fb-407a-b74a-e954d8f3fc42",
   "metadata": {},
   "source": [
    "### 1.5 一体化运行代码：获得验证后的A股股票清单：\n",
    "获取可信A股清单：\n",
    "- 国泰君安大智慧富易App，点击市场行情，A股后手工导出所有清单\n",
    "- AkShare采用京沪深A股实时行情接口（ak.stock_zh_a_spot_em），获得验证数据\n",
    "- 若国泰君安数据缺失，则检查是否这部分缺失数据的“最新价”为空，若是，则验证通过；否则，报警，验证不通过，并列出非空的股票清单。 \n",
    "- 对国泰君安数据做基本面校验，手工检查代码和简称没有错位情况。\n",
    "- 若验证通过，将该股票清单保存到共享stock数据库(/Users/mac/Downloads/同步空间/notebook/薛猫选股/Data/stock.db)，按照不同日期保存A股清单的快照。\n",
    "\n",
    "集中处理函数代码如下：**以下代码运行时，注意以下几点**\n",
    "- 按照1.2提示下载国泰君安股票清单到指定目录\n",
    "- 若不是断点继续，请删除同程序目录下faillist.pkl文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e788636f-eb8b-4e87-9c57-5b995443cf41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#get validated AshareList from AkShare and check\n",
    "# dblink: db link to store the validated AShare list\n",
    "# validlink: (optional) read from validlink of gtja data (.csv) for validation\n",
    "# fix: fix names from source automatically\n",
    "# current_date: 当前日期戳用于标记数据库表序号批次\n",
    "def storeAShareList(datalink,dblink,current_date,fix=False):\n",
    "    \n",
    "    gt_A=pd.read_csv(datalink,dtype={\"代码\":str})\n",
    "    \n",
    "    #validate source from AkShare\n",
    "    AKrealtimeA = ak.stock_zh_a_spot_em()\n",
    "    \n",
    "    #validate data\n",
    "    res={'valid':0,'diff':'','df':pd.DataFrame()}\n",
    "    AkGtjaDifDf=compareDiff(gt_A,AKrealtimeA,['代码'])\n",
    "    diffrate=AkGtjaDifDf.loc[0,'df22common']\n",
    "    if diffrate>0:\n",
    "        print(f'There is a {diffrate:.2%} gap comparing with AKShare verification data.')\n",
    "        AkGtjaDifList=AkGtjaDifDf['df2Diff'].tolist()[0].split(',')\n",
    "        df_filtered = AKrealtimeA[AKrealtimeA['代码'].isin(AkGtjaDifList)]\n",
    "        df_filtered2= df_filtered[df_filtered['最新价'].isna()]\n",
    "        AkDifAkNulldf=compareDiff(df_filtered,df_filtered2,['代码'])\n",
    "        if AkDifAkNulldf.loc[0,'df12common']==0:\n",
    "            res['valid']=1\n",
    "            print('All are of none quotes, pass the verification.')\n",
    "        else:\n",
    "            res['diff']=AkDifAkNulldf.loc[0,'df1Diff']\n",
    "            print('Check res[\\'diff\\'] to see details of shortage.')\n",
    "    else:\n",
    "        res['valid']=1\n",
    "        print(f'There is no data shortage from AKShare verification.')\n",
    "    \n",
    "    #check manually if not automatically fixed\n",
    "    file_path = 'faillist.pkl'\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "        print(f\"{file_path} deleted.\")\n",
    "    else:\n",
    "        print(f\"{file_path} no faillist file.\")\n",
    "    checkfound=checkFoundamental(gt_A,fix=fix)\n",
    "    \n",
    "    if res['valid']==0 and fix==False:\n",
    "        print('The difference of stock codes and its names from the verification source:\\n',checkfound['mismatch'])\n",
    "        m=''\n",
    "        while m.lower()!='y' and m.lower()!='n':\n",
    "            m=input('Check manually if the names pass the verification in accordance with the source(y/n)?')\n",
    "            if m.lower()=='n':\n",
    "                res['valid']=0\n",
    "            elif m.lower()!='y':\n",
    "                print('Only support press \\'y\\' or \\'n\\', press again.')\n",
    "            else:\n",
    "                res['valid']=1\n",
    "                \n",
    "    #store to database    \n",
    "    if res['valid']==1 or fix:\n",
    "        table_name =  \"Asharelist\" + current_date\n",
    "        conn = sqlite3.connect(dblink)\n",
    "        res['df']=checkfound['df'][['代码','名称','IPO']]\n",
    "        res['df'].to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "        conn.close()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab18b309-d5b2-4765-be49-539cced67ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a 5.13% gap comparing with AKShare verification data.\n",
      "All are of none quotes, pass the verification.\n",
      "faillist.pkl deleted.\n",
      "Try time 1:\n",
      "faillist(0):[]88708 checked: matched codes.                                                                 IPO:20241205\n",
      "All codes are checked and fixed.                                                                    \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>代码</th>\n",
       "      <th>名称</th>\n",
       "      <th>IPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>834765</td>\n",
       "      <td>美之高</td>\n",
       "      <td>2021-07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>871478</td>\n",
       "      <td>巨能股份</td>\n",
       "      <td>2023-05-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>838275</td>\n",
       "      <td>驱动力</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>831278</td>\n",
       "      <td>泰德股份</td>\n",
       "      <td>2022-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>837212</td>\n",
       "      <td>智新电子</td>\n",
       "      <td>2021-06-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5373</th>\n",
       "      <td>301622</td>\n",
       "      <td>英思特</td>\n",
       "      <td>2024-12-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5374</th>\n",
       "      <td>301617</td>\n",
       "      <td>博苑股份</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>301585</td>\n",
       "      <td>蓝宇股份</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5376</th>\n",
       "      <td>920098</td>\n",
       "      <td>科隆新材</td>\n",
       "      <td>2024-12-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5377</th>\n",
       "      <td>688708</td>\n",
       "      <td>佳驰科技</td>\n",
       "      <td>2024-12-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5378 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          代码    名称        IPO\n",
       "0     834765   美之高 2021-07-05\n",
       "1     871478  巨能股份 2023-05-12\n",
       "2     838275   驱动力 2021-01-25\n",
       "3     831278  泰德股份 2022-06-20\n",
       "4     837212  智新电子 2021-06-08\n",
       "...      ...   ...        ...\n",
       "5373  301622   英思特 2024-12-04\n",
       "5374  301617  博苑股份        NaT\n",
       "5375  301585  蓝宇股份        NaT\n",
       "5376  920098  科隆新材 2024-12-05\n",
       "5377  688708  佳驰科技 2024-12-05\n",
       "\n",
       "[5378 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dblink='/Users/mac/Downloads/同步空间/notebook/薛猫选股/Data/stock.db'\n",
    "result=storeAShareList(datalink,dblink,current_date,True)   #直接覆盖检查差异结果\n",
    "result['df']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84baccf5-1871-46e0-8f1a-459f55ba43c6",
   "metadata": {},
   "source": [
    "## 2. A股股票历史数据\n",
    "\n",
    "我们采用时序数据库 DolphinDB 来保存所有A股历史日数据信息。相关参考模板（https://docs.dolphindb.cn/zh/tutorials/stockdata_csv_import_demo.html）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83193887-1cdf-40dc-a551-3b8fcf061845",
   "metadata": {},
   "source": [
    "### 2.1 建立基准验证数据库：verifystock\n",
    "根据查询需求（查询特定股票的日线数据、具体日期段数据等），我们决定将股票代码（Symbol)作为数据库分区维度，时间作为数据表分区维度。（具体分区大小论证，见“A股验证后股票数据study1.ipynb”文档）  \n",
    "根据官方IT建议，可采用Datetime VALUE和SYMBOL HASH 30 方式复合分区。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ee05886-d8f2-43a0-9ec3-8504d3e5f644",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dolphindb as ddb\n",
    "import dolphindb.settings as keys\n",
    "\n",
    "#将gtja数据保存入verify stock库\n",
    "def createNativeDB(dbname,tablename):\n",
    "    #建立verifystock库\n",
    "    s = ddb.session(protocol=keys.PROTOCOL_DDB)\n",
    "    s.connect(\"localhost\", 8848,'admin','123456')\n",
    "\n",
    "    SQL=f'''\n",
    "    dbName=\"dfs://{dbname}\"\n",
    "    db1 = database(, RANGE, 1990.11.26 2010.11.26 2024.12.31)\n",
    "    db2 = database(, HASH, [SYMBOL, 30])\n",
    "    db = database(directory=dbName, partitionType=COMPO, partitionScheme=[db1, db2], engine=\"TSDB\")\n",
    "    '''\n",
    "\n",
    "    #建立gtja表\n",
    "    SQL2=f'''\n",
    "    tb=table(2000:0,[\"Symbol\",\"DateTime\", \"Open\",\"High\",\"Low\",\"Close\",\"Volume\"],[SYMBOL,DATE,DOUBLE,DOUBLE,DOUBLE,DOUBLE,INT])\n",
    "    db.createPartitionedTable(table=tb, tableName=`{tablename}, partitionColumns=`DateTime`Symbol,sortColumns=`DateTime)\n",
    "    '''\n",
    "    \n",
    "    s.run(SQL+SQL2)\n",
    "    s.close()\n",
    "\n",
    "#需要建库时，解除以下注释运行。\n",
    "#createNativeDB('verifystock','gtja')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9aad49-e2c4-4ff4-9c1d-c697a46e2f90",
   "metadata": {},
   "source": [
    "### 2.2 基准验证数据入库：国泰君安富易App2020年数据集\n",
    "\n",
    "通过国泰君安富易APP手工批量导出日线功能，实现全量A股有限日期导出(批量导出功能受限于2020年开始数据)。由于有限日期，作为校验线上数据AkShare使用。注意由于复权方法各软件存在差异，为避免校验出现偏差，我们一律采用不复权的价格和成交量数据。导出文件在：\n",
    "通过国泰君安富易App实现2020年至今数据全量A股导出csv文件（保存于Data/gtja_daily）,添加全部A股栏目，加入批量导出数据。  \n",
    "![export_A.png](export_A.png)\n",
    "\n",
    "App导出的文本数据文件：\n",
    "- 第一行是股票代码和名称等信息；第二行是表头，分隔符是tab（不论手工导出分隔符是什么，都是tab）；\n",
    "- 有两种格式文件，遇到股票名为生僻词，是GBK形式，而其它utf-8格式。因此，需要采用两种读取引擎读取文件。\n",
    "\n",
    "[涨停板敢死队](../涨停板敢死队/涨停板敢死队.ipynb) 中（2.2.4.2 获得基准验证数据：国泰君安富易App2020年数据集）详细记录了另一种较繁琐的方法，可以防止导出文件格式更新后，与原设定不一致的情况（目前没有发生）。为简化操作，我们采用根据数据自定义表头，跳过标题和表头与固定行跳过尾部非数据文本的方式，代码简化很多，但需要定期关注GTJA软件更新后，手工导出的数据格式变化。  \n",
    "\n",
    "#### 2.2.1 先读取国泰君安App数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e539234-42dc-4a5c-b889-24eee1b95370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import chardet\n",
    "import pandas as pd\n",
    "\n",
    "# 读取一个gtja文档并转化为DataFrame\n",
    "# skiplast：当在开始时导出国泰君安数据时，最后一天由于未收市，其股票记录数字不同于未来统计的真实情况，所以可以选择跳过最后一行。\n",
    "def readSingleGtja(file_path,skiplast=True):\n",
    "\n",
    "    # judgement of encoder\n",
    "    with open(file_path, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "        encoding = chardet.detect(raw_data)['encoding']\n",
    "\n",
    "    #When there're uncommon characters, the txt file is GBK encoding else UTF-8, so read with either decoder.\n",
    "    #print(f'{file_path} encoder:{encoding}',end='\\r')\n",
    "    if encoding=='GB2312':\n",
    "        encoding='GBK'\n",
    "    df = pd.read_csv(file_path, header=2, skipfooter=1,encoding=encoding)\n",
    "    if not df.empty:\n",
    "        names=['DateTime','Open','High','Low','Close','Volume','Amount']\n",
    "        df.rename(columns=dict(zip(df.columns, names)), inplace=True)\n",
    "        df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "        df.set_index('DateTime',inplace=True)\n",
    "        if skiplast:\n",
    "            df = df.drop(df.index[-1])\n",
    "    return df\n",
    "\n",
    "gtja_folder='Data/gtja_daily_bfq'\n",
    "#若需要测试，解除以下注释\n",
    "#readSingleGtja(gtja_folder+'/600016.txt')  #空文件：688605.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251bef37-25a9-4951-9e42-f446f4057fac",
   "metadata": {},
   "source": [
    "#### 2.2.2 将国泰君安A股历史验证数据存入verifystock库\n",
    "考虑到很有可能证券市场还没有关闭时导出的历史数据，所以当天价格成交量等信息，由于未结束，所以去掉最后一行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0a891b7-fdd7-4a51-95f7-dc6f9eeed30b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#保存验证数据到verifystock库gtja表\n",
    "# mode:数据库添加模式\n",
    "#      'append':会根据symbol和 DateTime 判断数据库已有记录，仅补全数据库中未有的记录。\n",
    "#      'replace':替换原有symbol的的记录\n",
    "def storeVerifystock(gtja_filename,dbname,tablename,mode='append',silent=False,skiplast=True):\n",
    "    \n",
    "    sym=os.path.basename(gtja_filename)[:6]\n",
    "    df=readSingleGtja(gtja_filename,skiplast).reset_index()\n",
    "\n",
    "    fail=None\n",
    "    if 'DateTime' in df.columns.to_list():\n",
    "        s = ddb.session(protocol=keys.PROTOCOL_DDB)\n",
    "        s.connect(\"localhost\", 8848,'admin','123456')\n",
    "        df['Symbol']=sym\n",
    "\n",
    "        if mode=='replace':\n",
    "            SQL_DELE=f'''\n",
    "            pt=loadTable(db,`{tablename})\n",
    "            delete from pt WHERE Symbol==`{sym}\n",
    "            '''\n",
    "            s.run(SQL_DELE)\n",
    "            iter_df=df\n",
    "        else:\n",
    "            SQL_QUERY=f'''\n",
    "            db=database(\"dfs://{dbname}\")\n",
    "            pt=loadTable(db,`{tablename})\n",
    "            select DateTime from pt where Symbol==`{sym};\n",
    "            '''\n",
    "            exist_df=s.run(SQL_QUERY)\n",
    "            if exist_df.empty:\n",
    "                iter_df=df\n",
    "            else:\n",
    "                iter_df = df[(df['DateTime'] > exist_df['DateTime'].max()) |\n",
    "                            (df['DateTime'] < exist_df['DateTime'].min())]\n",
    "            \n",
    "        num=0\n",
    "        if not iter_df.empty:\n",
    "            symbolStr='symbol=`'+'`'.join(iter_df['Symbol'].values)\n",
    "            dateStr='date='+' '.join(iter_df['DateTime'].dt.strftime('%Y.%m.%d').values)\n",
    "            openStr='open='+' '.join(iter_df['Open'].astype(str).values)\n",
    "            highStr='high='+' '.join(iter_df['High'].astype(str).values)\n",
    "            lowStr='low='+' '.join(iter_df['Low'].astype(str).values)\n",
    "            closeStr='close='+' '.join(iter_df['Close'].astype(str).values)\n",
    "            volStr='volume='+' '.join(iter_df['Volume'].astype(str).values)\n",
    "            SQL=f'''\n",
    "            tb = loadTable(\"dfs://{dbname}\",\"{tablename}\")\n",
    "            {symbolStr}\\n{dateStr}\\n{openStr}\\n{highStr}\\n{lowStr}\\n{closeStr}\\n{volStr}\n",
    "            temp=table(symbol,date,open,high,low,close,volume)\n",
    "            tableInsert(tb, temp);\n",
    "            '''\n",
    "            num=s.run(SQL)\n",
    "\n",
    "        msg='数据库中已经有所有记录，无需追加,' if num==0 else ''\n",
    "        if not silent:\n",
    "            print(f'{sym}{msg}完成{num}条记录导入',end='\\r')\n",
    "        s.close()\n",
    "    else:\n",
    "        msg=f'{sym}表数据无标准数据，跳过。'\n",
    "        fail=sym\n",
    "        if not silent:\n",
    "            print(msg,end='\\r')\n",
    "    return fail\n",
    "\n",
    "#需要调试时，解除以下注释运行。\n",
    "#storeVerifystock(gtja_folder+'/688602.txt','verifystock','gtja')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c204af14-cdf9-4e2b-90b5-f9a81c8854b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#将所有指定目录下的gtja股票数据文件经过校验后保存入\n",
    "def storeAllVerifystock(folder_path):\n",
    "    fails=[]\n",
    "    successes=[]\n",
    "    for filename in os.listdir(folder_path):\n",
    "        sym=filename[:6]\n",
    "        msg=f'正在导入{sym}...'\n",
    "        print(f'{msg:<100}',end='\\r')\n",
    "        \n",
    "        if filename[-4:]=='.txt':\n",
    "            fail=storeVerifystock(folder_path+'/'+filename,'verifystock','gtja')\n",
    "            if fail:\n",
    "                fails.append(fail)\n",
    "            else:\n",
    "                successes.append(sym)\n",
    "    \n",
    "    if len(fails)>0:\n",
    "        print(f'所有验证数据导入完毕.以下股票数据无标准数据：{fails}')\n",
    "    else:\n",
    "        print(f'完成所有验证数据导入.(总共{len(successes)})')\n",
    "    s.close()\n",
    "    return {'success':successes,'failure':fails}\n",
    "            \n",
    "            \n",
    "#需要调试时，解除以下注释运行。\n",
    "#storeAllVerifystock(gtja_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97909d7-86e1-4fef-8068-a4bdec273c0a",
   "metadata": {},
   "source": [
    "### 2.3 AkShare数据校验并入库\n",
    "#### 2.3.1 AkShare源获取数据和格式化\n",
    "我们采用东财数据源（后复权），我们将列替换为英文，并采用OHLCV字段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1db76235-e019-4be3-af18-5175897a9fcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>TurnOver</th>\n",
       "      <th>Market</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>600016</td>\n",
       "      <td>6.36</td>\n",
       "      <td>6.36</td>\n",
       "      <td>6.40</td>\n",
       "      <td>6.35</td>\n",
       "      <td>1043665</td>\n",
       "      <td>0.29</td>\n",
       "      <td>cn_stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>600016</td>\n",
       "      <td>6.37</td>\n",
       "      <td>6.34</td>\n",
       "      <td>6.38</td>\n",
       "      <td>6.34</td>\n",
       "      <td>599124</td>\n",
       "      <td>0.17</td>\n",
       "      <td>cn_stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>600016</td>\n",
       "      <td>6.32</td>\n",
       "      <td>6.30</td>\n",
       "      <td>6.37</td>\n",
       "      <td>6.28</td>\n",
       "      <td>802168</td>\n",
       "      <td>0.23</td>\n",
       "      <td>cn_stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>600016</td>\n",
       "      <td>6.32</td>\n",
       "      <td>6.33</td>\n",
       "      <td>6.36</td>\n",
       "      <td>6.30</td>\n",
       "      <td>574019</td>\n",
       "      <td>0.16</td>\n",
       "      <td>cn_stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>600016</td>\n",
       "      <td>6.32</td>\n",
       "      <td>6.29</td>\n",
       "      <td>6.33</td>\n",
       "      <td>6.26</td>\n",
       "      <td>693523</td>\n",
       "      <td>0.20</td>\n",
       "      <td>cn_stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>600016</td>\n",
       "      <td>3.96</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.99</td>\n",
       "      <td>3.93</td>\n",
       "      <td>2197577</td>\n",
       "      <td>0.62</td>\n",
       "      <td>cn_stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>2024-12-03</td>\n",
       "      <td>600016</td>\n",
       "      <td>3.97</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.04</td>\n",
       "      <td>3.97</td>\n",
       "      <td>2542357</td>\n",
       "      <td>0.72</td>\n",
       "      <td>cn_stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>2024-12-04</td>\n",
       "      <td>600016</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.01</td>\n",
       "      <td>2464741</td>\n",
       "      <td>0.70</td>\n",
       "      <td>cn_stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>600016</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4.02</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.01</td>\n",
       "      <td>1810655</td>\n",
       "      <td>0.51</td>\n",
       "      <td>cn_stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>2024-12-06</td>\n",
       "      <td>600016</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.02</td>\n",
       "      <td>2248575</td>\n",
       "      <td>0.63</td>\n",
       "      <td>cn_stock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1195 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DateTime  Symbol  Open  Close  High   Low   Volume  TurnOver    Market\n",
       "0    2020-01-02  600016  6.36   6.36  6.40  6.35  1043665      0.29  cn_stock\n",
       "1    2020-01-03  600016  6.37   6.34  6.38  6.34   599124      0.17  cn_stock\n",
       "2    2020-01-06  600016  6.32   6.30  6.37  6.28   802168      0.23  cn_stock\n",
       "3    2020-01-07  600016  6.32   6.33  6.36  6.30   574019      0.16  cn_stock\n",
       "4    2020-01-08  600016  6.32   6.29  6.33  6.26   693523      0.20  cn_stock\n",
       "...         ...     ...   ...    ...   ...   ...      ...       ...       ...\n",
       "1190 2024-12-02  600016  3.96   3.98  3.99  3.93  2197577      0.62  cn_stock\n",
       "1191 2024-12-03  600016  3.97   4.04  4.04  3.97  2542357      0.72  cn_stock\n",
       "1192 2024-12-04  600016  4.04   4.05  4.07  4.01  2464741      0.70  cn_stock\n",
       "1193 2024-12-05  600016  4.03   4.02  4.06  4.01  1810655      0.51  cn_stock\n",
       "1194 2024-12-06  600016  4.03   4.06  4.09  4.02  2248575      0.63  cn_stock\n",
       "\n",
       "[1195 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import akshare as ak\n",
    "\n",
    "# download akshare stock data(hfq) in the certain period, and format the data\n",
    "def getFormattedAkshare(symbol,start_date=None,end_date=None,fq=\"\"):\n",
    "    if end_date:\n",
    "        stock = ak.stock_zh_a_hist(symbol=symbol, period=\"daily\", start_date=start_date, end_date=end_date, adjust=fq)\n",
    "    else:\n",
    "        stock = ak.stock_zh_a_hist(symbol=symbol, period=\"daily\", start_date=start_date, adjust=fq)\n",
    "    if '日期' in stock.columns.to_list():\n",
    "        stock_res=stock[['日期','股票代码','开盘','收盘','最高','最低','成交量','换手率']]\n",
    "        stock_res=stock_res.rename(columns={\n",
    "            '日期': 'DateTime',\n",
    "            '股票代码': 'Symbol',\n",
    "            '开盘': 'Open',\n",
    "            '收盘': 'Close',\n",
    "            '最高': 'High',\n",
    "            '最低': 'Low',\n",
    "            '成交量': 'Volume',\n",
    "            '换手率': 'TurnOver'\n",
    "        })\n",
    "        stock_res['DateTime'] = pd.to_datetime(stock_res['DateTime'])\n",
    "        stock_res['Market'] = 'cn_stock'\n",
    "        stock_res.set_index('DateTime',inplace=True)\n",
    "    else:\n",
    "        stock_res=pd.DataFrame()\n",
    "    return stock_res\n",
    "\n",
    "#测试代码，需要调试时，可打开注释\n",
    "#getFormattedAkshare('600016','20200101').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1c88c6-c875-40ba-abe8-ff1c3eb9430f",
   "metadata": {},
   "source": [
    "#### 2.3.2 国泰君安本地数据校验"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b4667f-0369-4cd5-a7ce-ce976e8a2faa",
   "metadata": {},
   "source": [
    "国泰君安富易数据作校验(取值差异0.001作为阈值，即不超过0.1%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76fcb3d5-b68a-4369-bf8f-12ae26969031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compare the difference of two DataFrame of the same indexes\n",
    "# colList：columns list to compare\n",
    "# thresh: difference threshold\n",
    "def compareDiff2(tDf,vDf,thresh,colList):\n",
    "    compareind=vDf.index\n",
    "    targetdfcomp = tDf[tDf.index.isin(compareind)]\n",
    "    \n",
    "    #生成差异报告和超过阈值的差异报告（DataFrame）\n",
    "    comparedf=(targetdfcomp[colList]-vDf[colList])/(targetdfcomp[colList]+vDf[colList])*2 #差异报告\n",
    "    diff_df=comparedf[(comparedf.abs()>thresh).any(axis=1)] #超过阈值的差异报告\n",
    "    \n",
    "    #包含空值和非空值的差异统计率\n",
    "    non_null_count = comparedf.notna().sum().sum()\n",
    "    null_count = comparedf.isna().sum().sum()\n",
    "    diff_col_count = (comparedf.abs() > thresh).sum()\n",
    "    diff_count = diff_col_count.sum() \n",
    "    if non_null_count > 0:\n",
    "        commonRate = diff_count / non_null_count   #不包含空值的差异率\n",
    "    total_count = non_null_count + null_count\n",
    "    if total_count > 0:\n",
    "        totalRate = (diff_count + null_count) / total_count  #包含空值的差异率\n",
    "    \n",
    "    return {'diff_rate_not_null':commonRate,'total_diff_rate':totalRate,'compared_df':comparedf,'diff_df':diff_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70c8ee77-7766-44a4-a7c2-462a115d2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试代码，需要调试时，可打开注释\n",
    "#a=pd.DataFrame({'val':[1,2,3,4]})\n",
    "#b=pd.DataFrame({'val':[1,2,None,4.01]})\n",
    "#compareDiff2(a,b,0.13,['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bb739c-341d-45cd-9027-1dac85dd02ce",
   "metadata": {},
   "source": [
    "#### 2.3.3 建立dailystock数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db703028-4865-4304-878b-cf8cbc9035fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#需要建库时，解除以下注释运行。\n",
    "#createNativeDB('dailystock','ashare')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf65b727-cf89-468b-8bf4-c4ac2a45df2b",
   "metadata": {},
   "source": [
    "#### 2.3.4 读取验证数据(DolphinDB)\n",
    "从数据库中读取gtja验证数据（为支持断点续传，逐条存入DolphinDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a78f6cd-ec1e-4e49-9390-ec4115e0315d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#查询verifystock库中指定校验表tablename中指定symbol的DataFrame\n",
    "def getVerify(symbol,tablename):\n",
    "    s = ddb.session(protocol=keys.PROTOCOL_DDB)\n",
    "    s.connect(\"localhost\", 8848,'admin','123456')\n",
    "    \n",
    "    SQL=f'''\n",
    "    db=database(\"dfs://verifystock\")\n",
    "    pt=loadTable(db,`{tablename})\n",
    "    select DateTime,Open,High,Low,Close,Volume from pt where Symbol=`{symbol};\n",
    "    '''\n",
    "    res=s.run(SQL)\n",
    "    res['DateTime']=pd.to_datetime(res['DateTime'])\n",
    "    res=res.set_index('DateTime')\n",
    "    s.close()\n",
    "    return res\n",
    "\n",
    "#测试代码，需要调试时，可打开注释\n",
    "#getVerify('6000160','gtja').empty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefadec9-c16b-4596-830a-e51355e3a700",
   "metadata": {},
   "source": [
    "#### 2.4.2 校验下载AKShare并入库（DolphinDB）\n",
    "下载和验证函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1839e6b1-9e8a-4dde-8c66-233359ca965a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#按照symbol查询获取A股清单数据（本地sqllite3）指定字段信息\n",
    "# current_date:数据表后缀，指定版本的Asharelist表\n",
    "# collist: 指定返回的列值列表\n",
    "def getAsharelistBySymbol(dblink,current_date,symbol,collist):\n",
    "    conn = sqlite3.connect(dblink)\n",
    "    table_name =  \"Asharelist\" + current_date\n",
    "    colStr=','.join(collist)\n",
    "    Asharelist=pd.read_sql(f'select {colStr} from {table_name} where 代码={symbol}',conn,parse_dates=['IPO'])\n",
    "    return Asharelist\n",
    "\n",
    "#需要调试时，解除以下注释运行。\n",
    "#getAsharelistBySymbol(dblink,current_date,'6886012',['名称','IPO'])\n",
    "#getAsharelistBySymbol(dblink,current_date,'688602',['名称','IPO']).loc[0,'IPO'].strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c56d9397-2876-4a47-a71f-6725ab7b935b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600016</td>\n",
       "      <td>2000-12-19</td>\n",
       "      <td>20.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>18.50</td>\n",
       "      <td>18.56</td>\n",
       "      <td>1563524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600016</td>\n",
       "      <td>2000-12-20</td>\n",
       "      <td>18.47</td>\n",
       "      <td>18.47</td>\n",
       "      <td>17.91</td>\n",
       "      <td>18.10</td>\n",
       "      <td>290467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600016</td>\n",
       "      <td>2000-12-21</td>\n",
       "      <td>18.18</td>\n",
       "      <td>18.48</td>\n",
       "      <td>18.00</td>\n",
       "      <td>18.09</td>\n",
       "      <td>113629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600016</td>\n",
       "      <td>2000-12-22</td>\n",
       "      <td>18.10</td>\n",
       "      <td>18.17</td>\n",
       "      <td>17.60</td>\n",
       "      <td>17.66</td>\n",
       "      <td>130264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600016</td>\n",
       "      <td>2000-12-25</td>\n",
       "      <td>17.60</td>\n",
       "      <td>17.62</td>\n",
       "      <td>17.01</td>\n",
       "      <td>17.20</td>\n",
       "      <td>101131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5743</th>\n",
       "      <td>600016</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>3.96</td>\n",
       "      <td>3.99</td>\n",
       "      <td>3.93</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2197577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5744</th>\n",
       "      <td>600016</td>\n",
       "      <td>2024-12-03</td>\n",
       "      <td>3.97</td>\n",
       "      <td>4.04</td>\n",
       "      <td>3.97</td>\n",
       "      <td>4.04</td>\n",
       "      <td>2542357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5745</th>\n",
       "      <td>600016</td>\n",
       "      <td>2024-12-04</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.01</td>\n",
       "      <td>4.05</td>\n",
       "      <td>2464741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5746</th>\n",
       "      <td>600016</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.01</td>\n",
       "      <td>4.02</td>\n",
       "      <td>1810655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5747</th>\n",
       "      <td>600016</td>\n",
       "      <td>2024-12-06</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.02</td>\n",
       "      <td>4.06</td>\n",
       "      <td>2248575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5748 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Symbol   DateTime   Open   High    Low  Close   Volume\n",
       "0     600016 2000-12-19  20.00  21.00  18.50  18.56  1563524\n",
       "1     600016 2000-12-20  18.47  18.47  17.91  18.10   290467\n",
       "2     600016 2000-12-21  18.18  18.48  18.00  18.09   113629\n",
       "3     600016 2000-12-22  18.10  18.17  17.60  17.66   130264\n",
       "4     600016 2000-12-25  17.60  17.62  17.01  17.20   101131\n",
       "...      ...        ...    ...    ...    ...    ...      ...\n",
       "5743  600016 2024-12-02   3.96   3.99   3.93   3.98  2197577\n",
       "5744  600016 2024-12-03   3.97   4.04   3.97   4.04  2542357\n",
       "5745  600016 2024-12-04   4.04   4.07   4.01   4.05  2464741\n",
       "5746  600016 2024-12-05   4.03   4.06   4.01   4.02  1810655\n",
       "5747  600016 2024-12-06   4.03   4.09   4.02   4.06  2248575\n",
       "\n",
       "[5748 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a single stock data from AKshare from foundamental DataFrame stocklist and verified with validateDfs Dict\n",
    "# symbol:stock symbol\n",
    "# ipodayStr: A股清单库版本日期字符串\n",
    "# dfThresh: threshhold for judging DataFrame difference\n",
    "# valThresh: threshhold for judging value difference  \n",
    "# fq: 'qfq','hfq' and '' for forward,backward and none rights and devidend adjustments\n",
    "# strictVerify: 如果True，则严格限定在验证数据库范围内的股票，即不在此库中的股票一律不通过；\n",
    "#              如果False，则只排除验证数据库内股票校验不通过的股票，如果验证数据库内不存在目标股票，也通过。\n",
    "# ATTENTION: For the variety of methods unpublished, the verification DOES NOT verify adjust data,\n",
    "#   if the none adjust data pass the verification, then pass the adjust data \n",
    "# 注意单个检验函数并不检查:\n",
    "#    - symbol是否在verifystock库中，需要额外添加该逻辑。\n",
    "#    - foundDf['IPO']可能是NAT空值，需要额外添加逻辑处理。\n",
    "def getVerifiedAKShareSingle(symbol,ipodayStr,dfThresh,valThresh,fq,strictVerify=False):\n",
    "    res={}\n",
    "    if not asharelist.empty:\n",
    "        akshareDaily=getFormattedAkshare(symbol,ipodayStr)\n",
    "        validateDf=getVerify(symbol,'gtja')\n",
    "        \n",
    "        #如果验证数据库非空，则不论是否strictVerify，根据验证结果判断是否pass，并返回差异或者准确数据集\n",
    "        #如果验证数据库为空，若严格校验，则pass不通过，但返回准确数据集；若非严格校验，则pass通过，且返回准确数据集。\n",
    "        if not validateDf.empty:\n",
    "            validateDf['Volume']=(validateDf['Volume']/100).round()\n",
    "\n",
    "            comparelist=['Open','High','Low','Close','Volume']\n",
    "            comres=compareDiff2(validateDf,akshareDaily,valThresh,comparelist)\n",
    "            if comres['total_diff_rate']>=dfThresh:\n",
    "                res['pass']=False\n",
    "                res['diff_rate_not_null']=comres['diff_rate_not_null']\n",
    "                res['diff_df']=comres['diff_df']\n",
    "                res['total_diff_rate']=comres['total_diff_rate']\n",
    "            else:\n",
    "                res['pass']=True\n",
    "                res['df']=akshareDaily\n",
    "                res['IPOstr']=ipodayStr\n",
    "        elif strictVerify:\n",
    "            res['pass']=False\n",
    "            res['df']=akshareDaily\n",
    "            res['IPOstr']=ipodayStr\n",
    "        else:\n",
    "            res['pass']=True\n",
    "            res['df']=akshareDaily\n",
    "            res['IPOstr']=ipodayStr\n",
    "        \n",
    "    return res\n",
    "\n",
    "#测试代码，需要调试时，可打开注释\n",
    "\n",
    "#conn = sqlite3.connect(dblink)\n",
    "#symbol='600016'\n",
    "#table_name =  \"Asharelist\" + current_date\n",
    "#asharelist=pd.read_sql(f'select * from {table_name}',conn,parse_dates='IPO')\n",
    "#ipodayStr=asharelist.loc[asharelist['代码']==symbol,'IPO'].dt.strftime('%Y%m%d').values[0]\n",
    "#getVerifiedAKShareSingle('600016',ipodayStr,0.005,0.001,\"\")['df'].reset_index()[['Symbol','DateTime','Open','High','Low','Close','Volume']]\n",
    "#asharelist['代码'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582004a9-ca2d-4648-a57e-df0e61b04394",
   "metadata": {},
   "source": [
    "根据A股清单、gtja股票验证库（DolphinDB)遍历下载、搜集并验证数据(后复权)。   \n",
    "**注意事项**  \n",
    "- 需要运行打开DolphinDB\n",
    "- Data/storeVarified.txt文件是上一次运行过程文件，支持断点续传，但如果需要重新运行，需要手动删除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e0e1e51-abcc-47f8-823d-444f7a948a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all verified stock datas\n",
    "# strictVerify: 如果True，则严格限定在验证数据库范围内的股票，即不在此库中的股票一律不通过；\n",
    "#              如果False，则只排除验证数据库内股票校验不通过的股票，如果验证数据库内不存在目标股票，也通过。\n",
    "# loadTemp: 是否断点续传\n",
    "# dblink: A股清单Asharelist的数据库链接(sqlite3)\n",
    "# Asharelist表的当前版本日期：current_date\n",
    "def storeVerifiedAShareAll(dblink,current_date,dfThresh,valThresh,fq,strictVerify=False,loadTemp=True):\n",
    "    logfile='Data/storeVarified.txt'\n",
    "    successlist=[]\n",
    "    faillist=[]\n",
    "    if loadTemp:\n",
    "        contentlist=[]\n",
    "        if os.path.exists(logfile):\n",
    "            with open(logfile, 'r') as temp_file:\n",
    "                for line in temp_file:\n",
    "                    contentlist.append(line.strip())\n",
    "                    \n",
    "    conn = sqlite3.connect(dblink)\n",
    "    table_name =  \"Asharelist\" + current_date\n",
    "    asharelist=pd.read_sql(f'select * from {table_name}',conn,parse_dates='IPO')\n",
    "    \n",
    "    \n",
    "    if loadTemp:\n",
    "        asharelist=asharelist[~asharelist['代码'].isin(contentlist)]\n",
    "    \n",
    "    pool = ddb.DBConnectionPool(\"localhost\", 8848, 3, \"admin\", \"123456\")\n",
    "    appender = ddb.PartitionedTableAppender(dbPath=\"dfs://dailystock\", tableName=\"ashare\", partitionColName=\"Symbol\", dbConnectionPool=pool)\n",
    "    \n",
    "    total,no_fq,with_fq,fail_symbol,fail_with_no_IPO,fail_with_no_data,pass_with_no_IPO=0,0,0,0,0,0,0\n",
    "    for index, row in asharelist.iterrows():\n",
    "        symbol=row['代码']\n",
    "        ipodayStr=asharelist.loc[asharelist['代码']==symbol,'IPO'].dt.strftime('%Y%m%d').values[0]\n",
    "        msg=f'正在验证{symbol}...'\n",
    "        print(f'{msg:<100}',end='\\r')\n",
    "        if not pd.isna(row['IPO']):\n",
    "            singleres=getVerifiedAKShareSingle(symbol,ipodayStr,dfThresh,valThresh,fq,strictVerify=False)\n",
    "            singleresStr=singleres[\"pass\"]\n",
    "            msg=f'{symbol}校验结果:{singleresStr}'\n",
    "            print(f'{msg:<100}',end='\\r')\n",
    "            total+=1\n",
    "            if singleres['pass']:\n",
    "                if fq=='':\n",
    "                    app_df=singleres['df']\n",
    "                    no_fq+=1\n",
    "                else:\n",
    "                    msg=f'{symbol}获取从{ipodayStr}开始的数据...'\n",
    "                    print(f'{msg:<100}',end='\\r')\n",
    "                    app_df=getFormattedAkshare(symbol,ipodayStr,fq=fq)\n",
    "                    with_fq+=1\n",
    "                re=appender.append(app_df.reset_index()[['Symbol','DateTime','Open','High','Low','Close','Volume']])\n",
    "                successlist.append(symbol)\n",
    "                msg=f'{symbol}完成{re}条记录存储。'\n",
    "                print(f'{msg:<100}',end='\\r')\n",
    "            else:\n",
    "                fail_symbol+=1\n",
    "                msg=f'{symbol}数据有差异，总差异率{singleres[\"total_diff_rate\"]}...'\n",
    "                print(f'{msg:<100}',end='\\r')\n",
    "                faillist.append(symbol)\n",
    "        else:\n",
    "            if strictVerify:\n",
    "                msg=f'{symbol} IPO day missing.'\n",
    "                print(f'{msg:<100}',end='\\r')\n",
    "                faillist.append(symbol)\n",
    "                fail_with_no_IPO+=1\n",
    "            else:\n",
    "                gtfa=getFormattedAkshare(symbol,fq=fq)\n",
    "                if gtfa.empty:\n",
    "                    msg='No data before IPO day.'\n",
    "                    print(f'{msg:<100}',end='\\r')\n",
    "                    faillist.append(symbol)\n",
    "                    fail_with_no_data+=1\n",
    "                else:\n",
    "                    app_df=gtfa\n",
    "                    re=appender.append(app_df.reset_index()[['Symbol','DateTime','Open','High','Low','Close','Volume']])\n",
    "                    msg=f'没有IPO日期信息，{symbol}获取从头开始的数据{re}条导入数据库。'\n",
    "                    print(f'{msg:<100}',end='\\r')\n",
    "                    pass_with_no_IPO+=1\n",
    "                    \n",
    "        #记录已经处理的数据\n",
    "        with open(logfile, 'a') as file:\n",
    "            file.write(symbol+'\\n')\n",
    "                    \n",
    "    msg='完成所有A股信息下载和认证。'\n",
    "    print(f'{msg:<100}',end='\\r')\n",
    "    \n",
    "    return {'total':total,'no_fq':no_fq,'with_fq':with_fq,'fail_symbol':fail_symbol,'fail_with_no_IPO':fail_with_no_IPO,'fail_with_no_data':fail_with_no_data,'pass_with_no_IPO':pass_with_no_IPO}\n",
    "\n",
    "getRes=storeVerifiedAShareAll(dblink,current_date,0.005,0.001,'hfq')\n",
    "getRes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003fde58-c176-459d-ad0c-8d64f90e6e4f",
   "metadata": {},
   "source": [
    "### 2.5 将验证后的数据保存入dailystock数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e95567-b61c-482d-b0c4-b62b5621992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#需要建库时，解除以下注释运行。\n",
    "createNativeDB('dailystock','ashare')\n",
    "storeStock(getRes['dfs'],'verifystock','gtja')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39370f91-86d6-4904-b66a-30fb58e55b85",
   "metadata": {},
   "source": [
    "## 3. 附件：工具集和参考\n",
    "\n",
    "#### 数据处理过程参考：\n",
    "涨停板敢死队.ipynb\n",
    "\n",
    "#### 单个表结构查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24220adf-3246-4e56-a49f-1e81c0a8fc1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#如果需要使用工具，去掉以下注释\n",
    "#import sqlite3\n",
    "\n",
    "#get the field list of a table\n",
    "#def getStruct(filelink,table_name):\n",
    "#    conn = sqlite3.connect(filelink)\n",
    "#    cursor = conn.cursor()\n",
    "#    cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "#    fields = cursor.fetchall()\n",
    "#    conn.close()\n",
    "#    return [field[1] for field in fields]\n",
    "\n",
    "# getStruct(filelink,f'gtja_{symbol}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f32054-e6be-49f4-967d-08cddf5df374",
   "metadata": {},
   "source": [
    "#### AKShare查询个股信息和IPO等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0360a0-9403-48e7-9925-a37113de0661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#如果需要使用工具，去掉以下注释\n",
    "# b_df=ak.stock_individual_info_em('301551')\n",
    "# b_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabfc4f3-0959-43de-92ae-9313fa6b9461",
   "metadata": {},
   "source": [
    "#### Dolphin DB 数据维护工具\n",
    "删除指定表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6bc19c-f8b4-4dff-af5f-87fafebf8a92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#如果需要使用工具，去掉以下注释\n",
    "#s = ddb.Session()\n",
    "#s.connect(\"localhost\", 8848, \"admin\", \"123456\")\n",
    "#SQL='''\n",
    "#dbName=\"dfs://verifystock\"\n",
    "#dropDatabase(dbName)\n",
    "#'''\n",
    "#s.run(SQL)\n",
    "#s.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d907006d-eecd-46b3-8957-2127e307ff0a",
   "metadata": {},
   "source": [
    "删除数据，保留结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51cdc09-1ceb-422a-bff8-b5df4e3bbc74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#如果需要使用工具，去掉以下注释\n",
    "#s = ddb.Session()\n",
    "#s.connect(\"localhost\", 8848, \"admin\", \"123456\")\n",
    "#SQL='''\n",
    "#dbName=\"dfs://verifystock\"\n",
    "#truncate(dbName,`gtja)\n",
    "#'''\n",
    "\n",
    "#??为何报错在truncate中\n",
    "#s.run(SQL)\n",
    "#s.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b507ae18-f2b8-43f4-88b0-7538dfff2cbb",
   "metadata": {},
   "source": [
    "DolphinDB查询是否存在数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f32305-0106-4313-a990-e518cac3cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#如果需要使用工具，去掉以下注释\n",
    "#s = ddb.Session()\n",
    "#s.connect(\"localhost\", 8848, \"admin\", \"123456\")\n",
    "#SQL_QUERY=f'''\n",
    "#                db=database(\"dfs://dailystock\")\n",
    "#                pt=loadTable(db,`ashare)\n",
    "#                select * from pt;\n",
    "#                '''\n",
    "#exist_df=s.run(SQL_QUERY)\n",
    "#s.close()\n",
    "#exist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbfb092-19ab-411e-9bff-573063b62d6a",
   "metadata": {},
   "source": [
    "删除指定数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4a9166-75ae-49a5-8ec3-cf7c0a08a509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#如果需要使用工具，去掉以下注释\n",
    "#s = ddb.Session()\n",
    "#s.connect(\"localhost\", 8848, \"admin\", \"123456\")\n",
    "#SQL_QUERY=f'''\n",
    "#                db=database(\"dfs://verifystock\")\n",
    "#                pt=loadTable(db,`gtja)\n",
    "#                delete from pt where DateTime==2024.12.03;\n",
    "#                '''\n",
    "##exist_df=s.run(SQL_QUERY)  #当删除部分记录，非删除所有时，谨慎打开此项，会导致内存被库中记录占满。\n",
    "#s.run(SQL_QUERY)\n",
    "#s.close()\n",
    "#exist_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
